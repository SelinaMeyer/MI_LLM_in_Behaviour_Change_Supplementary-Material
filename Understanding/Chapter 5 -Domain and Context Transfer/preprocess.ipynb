{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac52824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.28.1)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Using cached thinc-8.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (813 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy) (63.1.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4\n",
      "  Using cached pydantic-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Using cached spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.7-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.22.4)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.2-py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Collecting smart-open<6.0.0,>=5.2.1\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.0.1-py3-none-any.whl (32 kB)\n",
      "Collecting blis<0.10.0,>=0.7.8\n",
      "  Using cached blis-0.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: wasabi, cymem, typer, spacy-loggers, spacy-legacy, smart-open, pydantic, murmurhash, langcodes, catalogue, blis, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.9.1 catalogue-2.0.8 confection-0.0.1 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.8 pathy-0.6.2 preshed-3.0.7 pydantic-1.9.2 smart-open-5.2.1 spacy-3.4.1 spacy-legacy-3.0.10 spacy-loggers-1.0.3 srsly-2.4.4 thinc-8.1.1 typer-0.4.2 wasabi-0.10.1\n",
      "2022-09-15 08:18:07.052444: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Collecting de-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.4.0/de_core_news_sm-3.4.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /opt/conda/lib/python3.9/site-packages (from de-core-news-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (63.1.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.64.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.9.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.22.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.0.1)\n",
      "Requirement already satisfied: blis<0.10.0,>=0.7.8 in /opt/conda/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.5.0,>=3.4.0->de-core-news-sm==3.4.0) (2.1.1)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.4.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f79f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 08:18:17.413854: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef58725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataset):\n",
    "    function = []\n",
    "    non_function = []\n",
    "    nonnoun = []\n",
    "    nonnoun_verb = []\n",
    "    nonverb = []\n",
    "    nonverb_aux = []\n",
    "    nonnoun_only = []\n",
    "    listofpostypes = ['AUX', 'ADP', 'DET', 'CONJ', 'PRON']\n",
    "    adj_nouns = ['ADJ', 'NOUN', 'PROPN']\n",
    "    adj_nouns_verbs = ['ADJ', 'NOUN', 'PROPN', 'VERB']\n",
    "    verbs = ['VERB']\n",
    "    verbs_aux = ['VERB', 'AUX']\n",
    "    nouns = ['NOUN', 'PROPN']\n",
    "\n",
    "    for index, example in enumerate(dataset[\"Sentence\"]):\n",
    "        func_sent = [token.text for token in nlp(example) if token.pos_ in listofpostypes]\n",
    "        nonfunc_sent = [token.text for token in nlp(example) if not token.pos_ in listofpostypes]\n",
    "        nonnoun_sent = [token.text for token in nlp(example) if not token.pos_ in adj_nouns]\n",
    "        nonnoun_verb_sent = [token.text for token in nlp(example) if not token.pos_ in adj_nouns_verbs]\n",
    "        nonverb_sent = [token.text for token in nlp(example) if not token.pos_ in verbs]\n",
    "        nonverb_aux_sent = [token.text for token in nlp(example) if not token.pos_ in verbs_aux]\n",
    "        nonnoun_only_sent = [token.text for token in nlp(example) if not token.pos_ in nouns]\n",
    "        function.append(' '.join(func_sent))\n",
    "        non_function.append(' '.join(nonfunc_sent))\n",
    "        nonnoun.append(' '.join(nonnoun_sent))\n",
    "        nonnoun_verb.append(' '.join(nonnoun_verb_sent))\n",
    "        nonverb.append(' '.join(nonverb_sent))\n",
    "        nonverb_aux.append(' '.join(nonverb_aux_sent))\n",
    "        nonnoun_only.append(' '.join(nonnoun_only_sent))\n",
    "        #negative = ([negative + 1 for token in nlp(example) if token.lemma_ in neg])\n",
    "    dataset[\"function_Sentence\"] = function\n",
    "    dataset[\"nonfunction_Sentence\"] = non_function\n",
    "    dataset[\"non_noun_adj\"] = nonnoun\n",
    "    dataset[\"non_noun_verb_adj\"] = nonnoun_verb\n",
    "    dataset[\"non_verb\"] = nonverb\n",
    "    dataset[\"non_verb_aux\"] = nonverb_aux\n",
    "    dataset[\"non_noun\"] = nonnoun_only\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c994479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data = pd.read_csv(\"forum/label_train_preproc_drop.csv\", index_col=\"Unnamed: 0\")\n",
    "#Labels:\n",
    "'''datasets = [\"01_random_split/label_test.csv\", \"03_non_smoking/nichtraucher_labels_v2.csv\",\n",
    "            \"04_synthetic/output_labels.csv\", \"05_optifast/optifast_labels.csv\", \n",
    "            \"06_instagram_data/instagram_labels.csv\", \"07_VirtualCoachData/virtual_coach_labels.csv\",\n",
    "            \"08_WoZ/WoZ_labels.csv\"]'''\n",
    "\n",
    "#sublabels\n",
    "'''datasets = [\"01_random_split/sublabel_train.csv\", \"01_random_split/sublabel_test.csv\", \"03_non_smoking/nichtraucher_sublabels_v2.csv\",\n",
    "            \"04_synthetic/output_sublabels.csv\", \"05_optifast/optifast_sublabels.csv\", \n",
    "            \"06_instagram_data/instagram_sublabels.csv\", \"07_VirtualCoachData/virtual_coach_sublabels.csv\",\n",
    "            \"08_WoZ/WoZ_sublabels.csv\"]\n",
    "\n",
    "names = [\"train\", \"test\", \"nonsmoking\", \"synthetic\", \"optifast\", \"instagram\", \"virtualcoach\", \"WoZ\"]'''\n",
    "\n",
    "#valence\n",
    "datasets = [\"01_random_split/binary_train.csv\", \"01_random_split/binary_test.csv\", \"03_non_smoking/nichtraucher_valence_v2.csv\",\n",
    "            \"05_optifast/optifast_valence.csv\",  \"04_synthetic/output_valences.csv\",\n",
    "            \"07_VirtualCoachData/virtual_coach_valence.csv\", \"08_WoZ/WoZ_valence.csv\"]\n",
    "\n",
    "names = [\"train\", \"test\", \"nonsmoking\", \"optifast\", \"synthetic\", \"virtualcoach\", \"WoZ\"]\n",
    "\n",
    "for index, i in enumerate(datasets):\n",
    "    test_data = pd.read_csv(\"../MI_Data/Bert_Finetuning/\" + i, index_col=\"Unnamed: 0\")\n",
    "    test_data_prep = preprocessing(test_data)\n",
    "    nan_value = float(\"NaN\")\n",
    "    test_data_prep.replace(\"\", nan_value, inplace=True)\n",
    "    test_data_prep.dropna(how='any', inplace=True)\n",
    "    set_name = str(names[index])\n",
    "    #test_data_prep.to_csv(\"forum/labels/\"+set_name+\"_label_preproc.csv\")\n",
    "    #test_data_prep.to_csv(\"forum/sublabels/\"+set_name+\"_sublabel_preproc.csv\")\n",
    "    test_data_prep.to_csv(\"forum/valence/\"+set_name+\"_valence_preproc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eeaf4e5-bcea-4eb6-9c8a-32f7b667414a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>function_Sentence</th>\n",
       "      <th>nonfunction_Sentence</th>\n",
       "      <th>non_noun_adj</th>\n",
       "      <th>non_noun_verb_adj</th>\n",
       "      <th>non_verb</th>\n",
       "      <th>non_verb_aux</th>\n",
       "      <th>non_noun</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0</td>\n",
       "      <td>Ich bin mir sicher, ich schaffe es ohne OP ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ich bin mir ich es ohne für mich ist es eine</td>\n",
       "      <td>sicher , schaffe OP nicht , hilfreiche Krücke .</td>\n",
       "      <td>Ich bin mir sicher , ich schaffe es ohne nic...</td>\n",
       "      <td>Ich bin mir sicher , ich es ohne nicht , für...</td>\n",
       "      <td>Ich bin mir sicher , ich es ohne OP nicht , ...</td>\n",
       "      <td>Ich mir sicher , ich es ohne OP nicht , für ...</td>\n",
       "      <td>Ich bin mir sicher , ich schaffe es ohne nic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>1</td>\n",
       "      <td>Ich Frage mich vor jedem Essen kurz: Brauche ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ich mich vor jedem ich das</td>\n",
       "      <td>Frage Essen kurz : Brauche jetzt ?</td>\n",
       "      <td>Ich mich vor jedem kurz : Brauche ich das je...</td>\n",
       "      <td>Ich mich vor jedem kurz : ich das jetzt ?</td>\n",
       "      <td>Ich Frage mich vor jedem Essen kurz : ich da...</td>\n",
       "      <td>Ich Frage mich vor jedem Essen kurz : ich da...</td>\n",
       "      <td>Ich mich vor jedem kurz : Brauche ich das je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>2</td>\n",
       "      <td>Ich weiß zwar was was hat und wie viel ich da...</td>\n",
       "      <td>1</td>\n",
       "      <td>Ich was was viel ich zu mir es auf</td>\n",
       "      <td>weiß zwar hat und wie dann ca nehme , schrei...</td>\n",
       "      <td>Ich weiß zwar was was hat und wie viel ich d...</td>\n",
       "      <td>Ich zwar was was und wie viel ich dann zu mi...</td>\n",
       "      <td>Ich zwar was was und wie viel ich dann ca zu...</td>\n",
       "      <td>Ich zwar was was und wie viel ich dann ca zu...</td>\n",
       "      <td>Ich weiß zwar was was hat und wie viel ich d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>3</td>\n",
       "      <td>Mein Gewicht steht so rum und ich finde, es k...</td>\n",
       "      <td>0</td>\n",
       "      <td>Mein ich es könnte</td>\n",
       "      <td>Gewicht steht so rum und finde , noch etwas ...</td>\n",
       "      <td>Mein steht so rum und ich finde , es könnte ...</td>\n",
       "      <td>Mein so rum und ich , es könnte noch etwas m...</td>\n",
       "      <td>Mein Gewicht so rum und ich , es könnte noch...</td>\n",
       "      <td>Mein Gewicht so rum und ich , es noch etwas ...</td>\n",
       "      <td>Mein steht so rum und ich finde , es könnte ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>4</td>\n",
       "      <td>mit dem Entschluss - du musst was dagegen unte...</td>\n",
       "      <td>0</td>\n",
       "      <td>mit dem du was</td>\n",
       "      <td>Entschluss - musst dagegen unternehmen .</td>\n",
       "      <td>mit dem - du musst was dagegen unternehmen .</td>\n",
       "      <td>mit dem - du was dagegen .</td>\n",
       "      <td>mit dem Entschluss - du was dagegen .</td>\n",
       "      <td>mit dem Entschluss - du was dagegen .</td>\n",
       "      <td>mit dem - du musst was dagegen unternehmen .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0.1                                           Sentence  \\\n",
       "Unnamed: 0                                                                    \n",
       "1779                   0   Ich bin mir sicher, ich schaffe es ohne OP ni...   \n",
       "3475                   1   Ich Frage mich vor jedem Essen kurz: Brauche ...   \n",
       "3591                   2   Ich weiß zwar was was hat und wie viel ich da...   \n",
       "1503                   3   Mein Gewicht steht so rum und ich finde, es k...   \n",
       "496                    4  mit dem Entschluss - du musst was dagegen unte...   \n",
       "\n",
       "            labels                             function_Sentence  \\\n",
       "Unnamed: 0                                                         \n",
       "1779             0  Ich bin mir ich es ohne für mich ist es eine   \n",
       "3475             1                    Ich mich vor jedem ich das   \n",
       "3591             1            Ich was was viel ich zu mir es auf   \n",
       "1503             0                            Mein ich es könnte   \n",
       "496              0                                mit dem du was   \n",
       "\n",
       "                                         nonfunction_Sentence  \\\n",
       "Unnamed: 0                                                      \n",
       "1779          sicher , schaffe OP nicht , hilfreiche Krücke .   \n",
       "3475                       Frage Essen kurz : Brauche jetzt ?   \n",
       "3591          weiß zwar hat und wie dann ca nehme , schrei...   \n",
       "1503          Gewicht steht so rum und finde , noch etwas ...   \n",
       "496                  Entschluss - musst dagegen unternehmen .   \n",
       "\n",
       "                                                 non_noun_adj  \\\n",
       "Unnamed: 0                                                      \n",
       "1779          Ich bin mir sicher , ich schaffe es ohne nic...   \n",
       "3475          Ich mich vor jedem kurz : Brauche ich das je...   \n",
       "3591          Ich weiß zwar was was hat und wie viel ich d...   \n",
       "1503          Mein steht so rum und ich finde , es könnte ...   \n",
       "496              mit dem - du musst was dagegen unternehmen .   \n",
       "\n",
       "                                            non_noun_verb_adj  \\\n",
       "Unnamed: 0                                                      \n",
       "1779          Ich bin mir sicher , ich es ohne nicht , für...   \n",
       "3475                Ich mich vor jedem kurz : ich das jetzt ?   \n",
       "3591          Ich zwar was was und wie viel ich dann zu mi...   \n",
       "1503          Mein so rum und ich , es könnte noch etwas m...   \n",
       "496                                mit dem - du was dagegen .   \n",
       "\n",
       "                                                     non_verb  \\\n",
       "Unnamed: 0                                                      \n",
       "1779          Ich bin mir sicher , ich es ohne OP nicht , ...   \n",
       "3475          Ich Frage mich vor jedem Essen kurz : ich da...   \n",
       "3591          Ich zwar was was und wie viel ich dann ca zu...   \n",
       "1503          Mein Gewicht so rum und ich , es könnte noch...   \n",
       "496                     mit dem Entschluss - du was dagegen .   \n",
       "\n",
       "                                                 non_verb_aux  \\\n",
       "Unnamed: 0                                                      \n",
       "1779          Ich mir sicher , ich es ohne OP nicht , für ...   \n",
       "3475          Ich Frage mich vor jedem Essen kurz : ich da...   \n",
       "3591          Ich zwar was was und wie viel ich dann ca zu...   \n",
       "1503          Mein Gewicht so rum und ich , es noch etwas ...   \n",
       "496                     mit dem Entschluss - du was dagegen .   \n",
       "\n",
       "                                                     non_noun  \n",
       "Unnamed: 0                                                     \n",
       "1779          Ich bin mir sicher , ich schaffe es ohne nic...  \n",
       "3475          Ich mich vor jedem kurz : Brauche ich das je...  \n",
       "3591          Ich weiß zwar was was hat und wie viel ich d...  \n",
       "1503          Mein steht so rum und ich finde , es könnte ...  \n",
       "496              mit dem - du musst was dagegen unternehmen .  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv(\"forum/label_train_preproc_drop.csv\", index_col=\"Unnamed: 0\")\n",
    "training_data_proc = preprocessing(training_data)\n",
    "nan_value = float(\"NaN\")\n",
    "training_data_proc.replace(\"\", nan_value, inplace=True)\n",
    "training_data_proc.dropna(how='any', inplace=True)\n",
    "training_data_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e5c83ff-971f-48d1-b73d-8f4b95bc2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_csv(\"forum/label_train_preproc_drop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfbcf19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
