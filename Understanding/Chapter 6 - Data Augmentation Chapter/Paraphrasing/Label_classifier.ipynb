{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install keras\n",
    "!pip install Sentencepiece\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip install datasets\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 07:21:28.621234: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "#import keras\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions import *\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c1264bb66281b4f8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/jovyan/.cache/huggingface/datasets/csv/default-c1264bb66281b4f8/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1741aeedd1a0419e8e19f99b6b1ff8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "777629bb6b234acebc4f7babc5d24bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/jovyan/.cache/huggingface/datasets/csv/default-c1264bb66281b4f8/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2683071d488e4be6b9784dcd254fd14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c1264bb66281b4f8\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-c1264bb66281b4f8/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bade2aaa16a4f7c9e9edfa00005ab54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71d0f2628f74e1bb52e2783a1fa2ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6d7db1eb954ee1975e66ec1df1168e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823f8483ea9241c284cc718e3e2b8b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e541c1d9736462389eff5491b0166df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c71f4c0769f4fd59bbe564307acf02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ec78709ad944cea43508e5493817ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8396dadcd5ed41b5854f343aa48823fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade3d434d76540868079ec2c57d2de29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cc8c3ff94c4f1a8a8fed1d21db078f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd43904ee57d434bb77c7094a45f1e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22225ee0778402fbd703a0bb399d028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d741af935149a59ab5fc4af3038dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475aebbb296c4f9db56caf54377d2679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ec73501ed74efdb0376fd7127df441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a842d8b1aae0481a95acc249c1b604fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73653979922e4a06b46f97be3dcee3e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f548bb741f7488d8606110fdff61f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7605174e8b8d44d397fabfa04ad64e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b14169ecf14b30ad02077bde2d0dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cc1bde275b4882a82efd62e290ebfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#forum_vals, forum_trains = load_and_tokenize_training_set(\"1-forum-only/Forum_label_train.csv\")\n",
    "forum_vals, forum_trains = load_and_tokenize_training_set(\"paraphrased_label_train_sim_lower_4_20.csv\", \"Sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\"preproc_forum\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5206\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.602800</td>\n",
       "      <td>0.618746</td>\n",
       "      <td>0.801038</td>\n",
       "      <td>0.689202</td>\n",
       "      <td>0.776587</td>\n",
       "      <td>0.647242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.350500</td>\n",
       "      <td>0.671066</td>\n",
       "      <td>0.826990</td>\n",
       "      <td>0.757073</td>\n",
       "      <td>0.782063</td>\n",
       "      <td>0.741375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.972474</td>\n",
       "      <td>0.851211</td>\n",
       "      <td>0.790758</td>\n",
       "      <td>0.851269</td>\n",
       "      <td>0.752655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4726c2318647a39fabe88f39754d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db51236124d748c9be26b24030b4b6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e855faf271496db1beb2cbaebf1690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5813144b70c54151999e2f2acbd4f884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d1f3cfeba74e5987c246bba847651f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6214052c964675966b541dc7197a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384cb563540b414c86e3621662d6116c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8338624338624339, 'f1': 0.7445050248946855, 'precision': 0.7946843670260727, 'recall': 0.7127519440353666}, 'Instagram Data': {'accuracy': 0.6644736842105263, 'f1': 0.6054886011851712, 'precision': 0.661119126418811, 'recall': 0.5936640502354787}, 'Smoke Stop Forum': {'accuracy': 0.7730600292825769, 'f1': 0.6844051551235659, 'precision': 0.7362075140877424, 'recall': 0.6539998079323922}, 'Synthetic GPT3 Data': {'accuracy': 0.8918918918918919, 'f1': 0.8442612942612944, 'precision': 0.8280672268907563, 'recall': 0.870234703568037}, 'Health Coach Dialogue Corpus': {'accuracy': 0.6515748031496063, 'f1': 0.644870337133028, 'precision': 0.7262671463250564, 'recall': 0.6556992027580263}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.7625, 'f1': 0.7666666666666666, 'precision': 0.8025175882318739, 'recall': 0.7895622895622895}, 'Optifast Mock-Chatbot': {'accuracy': 0.7777777777777778, 'f1': 0.644537967236854, 'precision': 0.6567460317460317, 'recall': 0.6531590413943356}}\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/5236eea09283e87ba7c16d0571a12520ed4f076869f3d943fdbfaaa34b71e419.953a553bf3928a893b8cacf8d8c46ce6c565c095f062120aa0773821285cde25\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5205\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.602700</td>\n",
       "      <td>0.429696</td>\n",
       "      <td>0.844560</td>\n",
       "      <td>0.771032</td>\n",
       "      <td>0.811965</td>\n",
       "      <td>0.743752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.622140</td>\n",
       "      <td>0.835924</td>\n",
       "      <td>0.779366</td>\n",
       "      <td>0.791488</td>\n",
       "      <td>0.772019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.184700</td>\n",
       "      <td>0.727638</td>\n",
       "      <td>0.851468</td>\n",
       "      <td>0.796215</td>\n",
       "      <td>0.808854</td>\n",
       "      <td>0.786790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad6e06477bb49659b55e11ec4aa96f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1758a3ea3524b1da0f7003e7b18afcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4628ed823aac43a3abfe7367c0de48e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861de61a91245769fb4c50b7cdfb19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d030bf1b49545fcad073080214ed365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087f3d2928c54444a8ec042b1a49140b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca26b5a2579472c9354955a03efb9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8317460317460318, 'f1': 0.7537692277881773, 'precision': 0.7856430291414811, 'recall': 0.729947364974103}, 'Instagram Data': {'accuracy': 0.6885964912280702, 'f1': 0.6445826530746966, 'precision': 0.6914119607007837, 'recall': 0.6297980115122973}, 'Smoke Stop Forum': {'accuracy': 0.7833089311859444, 'f1': 0.7011515054993316, 'precision': 0.727330696868553, 'recall': 0.6812457985210795}, 'Synthetic GPT3 Data': {'accuracy': 0.8918918918918919, 'f1': 0.847094177476816, 'precision': 0.8043083900226756, 'recall': 0.9116809116809117}, 'Health Coach Dialogue Corpus': {'accuracy': 0.7007874015748031, 'f1': 0.6969662369295119, 'precision': 0.7352399934383201, 'recall': 0.7006176829706242}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.8, 'f1': 0.8141025641025642, 'precision': 0.840896311291048, 'recall': 0.8392255892255892}, 'Optifast Mock-Chatbot': {'accuracy': 0.7555555555555555, 'f1': 0.6453748006379586, 'precision': 0.6276106934001671, 'recall': 0.6718020541549953}}\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/5236eea09283e87ba7c16d0571a12520ed4f076869f3d943fdbfaaa34b71e419.953a553bf3928a893b8cacf8d8c46ce6c565c095f062120aa0773821285cde25\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5206\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.594700</td>\n",
       "      <td>0.490430</td>\n",
       "      <td>0.825260</td>\n",
       "      <td>0.744528</td>\n",
       "      <td>0.753523</td>\n",
       "      <td>0.744821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.346900</td>\n",
       "      <td>0.579887</td>\n",
       "      <td>0.837370</td>\n",
       "      <td>0.774768</td>\n",
       "      <td>0.766845</td>\n",
       "      <td>0.783928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.722402</td>\n",
       "      <td>0.868512</td>\n",
       "      <td>0.821938</td>\n",
       "      <td>0.835757</td>\n",
       "      <td>0.810802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19a3a2192f142408bca670446538b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8879db2cac46d18d445c022d4cdd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f11f6ac511a4276a86827473ad55144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57418dffa19d4f7fa15ab6f1998e53f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0172b69f0840d38f1e2e41eda94f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7969e58521ca4bb89f42cc37448e7834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd49d6d363147aab6aab8e76d919402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8137566137566138, 'f1': 0.7332064563439641, 'precision': 0.749093886174264, 'recall': 0.7198553575558924}, 'Instagram Data': {'accuracy': 0.6918859649122807, 'f1': 0.6474781538599518, 'precision': 0.6751382128694837, 'recall': 0.6379794174079888}, 'Smoke Stop Forum': {'accuracy': 0.7920937042459737, 'f1': 0.7047851160078951, 'precision': 0.7425627006034353, 'recall': 0.680126404494382}, 'Synthetic GPT3 Data': {'accuracy': 0.9054054054054054, 'f1': 0.8504854368932039, 'precision': 0.8186274509803922, 'recall': 0.8958757292090626}, 'Health Coach Dialogue Corpus': {'accuracy': 0.7224409448818898, 'f1': 0.7226305779149857, 'precision': 0.7615221758345979, 'recall': 0.7261761114702292}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.8125, 'f1': 0.8134590000418092, 'precision': 0.8296296296296296, 'recall': 0.8501683501683502}, 'Optifast Mock-Chatbot': {'accuracy': 0.7444444444444445, 'f1': 0.6150942028985508, 'precision': 0.613151364764268, 'recall': 0.6235605353252412}}\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/5236eea09283e87ba7c16d0571a12520ed4f076869f3d943fdbfaaa34b71e419.953a553bf3928a893b8cacf8d8c46ce6c565c095f062120aa0773821285cde25\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5205\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.409708</td>\n",
       "      <td>0.851468</td>\n",
       "      <td>0.750285</td>\n",
       "      <td>0.811175</td>\n",
       "      <td>0.711418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>0.549745</td>\n",
       "      <td>0.875648</td>\n",
       "      <td>0.807814</td>\n",
       "      <td>0.834007</td>\n",
       "      <td>0.789711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.642666</td>\n",
       "      <td>0.872193</td>\n",
       "      <td>0.791163</td>\n",
       "      <td>0.814652</td>\n",
       "      <td>0.771818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043462eceb40481bac3fd1814b449fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8732e7cde1f44b3cbf1f4361d4b81aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e041ef51cd45e7aa99cf43c28c597e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399ddefd7e4d4cc3b08dd69dcfcc5082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b4ec48335d44e8b0639756829555da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6054eb49c1f54bc382c931d2ee9370b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799d5b730ed749b188b8040fb0415fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8275132275132275, 'f1': 0.7546946103987805, 'precision': 0.787447959723846, 'recall': 0.7300543089313143}, 'Instagram Data': {'accuracy': 0.680921052631579, 'f1': 0.6290114138041617, 'precision': 0.6799588855895844, 'recall': 0.6152694924123495}, 'Smoke Stop Forum': {'accuracy': 0.7906295754026355, 'f1': 0.7000234925960784, 'precision': 0.7526474622770918, 'recall': 0.669181551906271}, 'Synthetic GPT3 Data': {'accuracy': 0.8918918918918919, 'f1': 0.8632478632478633, 'precision': 0.869281045751634, 'recall': 0.870234703568037}, 'Health Coach Dialogue Corpus': {'accuracy': 0.6515748031496063, 'f1': 0.6436351944480071, 'precision': 0.7120674833440791, 'recall': 0.6541729512317748}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.75, 'f1': 0.7324866712719414, 'precision': 0.7510064412238325, 'recall': 0.7794612794612794}, 'Optifast Mock-Chatbot': {'accuracy': 0.7222222222222222, 'f1': 0.5910150455605002, 'precision': 0.5847701149425287, 'recall': 0.6129785247432307}}\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/5236eea09283e87ba7c16d0571a12520ed4f076869f3d943fdbfaaa34b71e419.953a553bf3928a893b8cacf8d8c46ce6c565c095f062120aa0773821285cde25\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5206\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.601200</td>\n",
       "      <td>0.383226</td>\n",
       "      <td>0.859862</td>\n",
       "      <td>0.787172</td>\n",
       "      <td>0.825834</td>\n",
       "      <td>0.761090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.487241</td>\n",
       "      <td>0.878893</td>\n",
       "      <td>0.818480</td>\n",
       "      <td>0.838155</td>\n",
       "      <td>0.804557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.681360</td>\n",
       "      <td>0.870242</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.821933</td>\n",
       "      <td>0.793378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c337f5c9bd04c6f8159a81e0f2e73fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359bb2c89e284280be152b5e62545822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22819b5c7ea042e4a769c9567171d7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd22345db154cbf9c7c8f20d870afa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d1ca7af0bd48daa71a024b28c9e896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2d52250cb24631aab44b737c5d2ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b64234b4c6b4be98b854b608f902c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8243386243386244, 'f1': 0.7513541653125841, 'precision': 0.7726848539057842, 'recall': 0.7340369078336993}, 'Instagram Data': {'accuracy': 0.6918859649122807, 'f1': 0.6477498512828835, 'precision': 0.6952418237941963, 'recall': 0.6324646781789639}, 'Smoke Stop Forum': {'accuracy': 0.7862371888726208, 'f1': 0.6960837026195605, 'precision': 0.7241714353838816, 'recall': 0.6776085181984058}, 'Synthetic GPT3 Data': {'accuracy': 0.9054054054054054, 'f1': 0.8609309054031885, 'precision': 0.8412698412698413, 'recall': 0.8958757292090626}, 'Health Coach Dialogue Corpus': {'accuracy': 0.6929133858267716, 'f1': 0.690710755040237, 'precision': 0.7293812295883656, 'recall': 0.6963082668965023}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.8125, 'f1': 0.8054383497421472, 'precision': 0.8101928755998523, 'recall': 0.8501683501683502}, 'Optifast Mock-Chatbot': {'accuracy': 0.7222222222222222, 'f1': 0.5856195015152121, 'precision': 0.5935140882509303, 'recall': 0.6261126672891378}}\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/5236eea09283e87ba7c16d0571a12520ed4f076869f3d943fdbfaaa34b71e419.953a553bf3928a893b8cacf8d8c46ce6c565c095f062120aa0773821285cde25\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5206\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.474990</td>\n",
       "      <td>0.840830</td>\n",
       "      <td>0.777632</td>\n",
       "      <td>0.813400</td>\n",
       "      <td>0.753503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.341400</td>\n",
       "      <td>0.558514</td>\n",
       "      <td>0.854671</td>\n",
       "      <td>0.801486</td>\n",
       "      <td>0.807730</td>\n",
       "      <td>0.797882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.192600</td>\n",
       "      <td>0.759857</td>\n",
       "      <td>0.870242</td>\n",
       "      <td>0.828312</td>\n",
       "      <td>0.863113</td>\n",
       "      <td>0.801492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67714879e57841acacb848cf8bddbb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28e60b36aa94272887e9b279d26bea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4c0c2aa232439c92be4e24bff2867d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279779fb7f4e4a919d3f9d8d51199df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fd16bff96a4143b45e03f572f4df60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9ae92d422c4ceeb0262338c7b210d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2003d83f1143c4aa8087ea3e98b438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8338624338624339, 'f1': 0.7560117086863883, 'precision': 0.7880867684195975, 'recall': 0.7318694377517908}, 'Instagram Data': {'accuracy': 0.6765350877192983, 'f1': 0.6348296166950037, 'precision': 0.663817085496, 'recall': 0.6244297924297925}, 'Smoke Stop Forum': {'accuracy': 0.7950219619326501, 'f1': 0.7150859268324027, 'precision': 0.7430982714001582, 'recall': 0.6939096561989819}, 'Synthetic GPT3 Data': {'accuracy': 0.8378378378378378, 'f1': 0.7774719673802242, 'precision': 0.7704545454545455, 'recall': 0.7896486229819564}, 'Health Coach Dialogue Corpus': {'accuracy': 0.6948818897637795, 'f1': 0.6945494669082602, 'precision': 0.7378063850334525, 'recall': 0.697224017812253}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.8, 'f1': 0.8241196144009443, 'precision': 0.8594402673350041, 'recall': 0.8392255892255892}, 'Optifast Mock-Chatbot': {'accuracy': 0.7666666666666667, 'f1': 0.6026426426426427, 'precision': 0.6040322580645162, 'recall': 0.606691565515095}}\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/5236eea09283e87ba7c16d0571a12520ed4f076869f3d943fdbfaaa34b71e419.953a553bf3928a893b8cacf8d8c46ce6c565c095f062120aa0773821285cde25\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5205\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.447066</td>\n",
       "      <td>0.841105</td>\n",
       "      <td>0.752477</td>\n",
       "      <td>0.771097</td>\n",
       "      <td>0.736916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.663665</td>\n",
       "      <td>0.846287</td>\n",
       "      <td>0.776870</td>\n",
       "      <td>0.764660</td>\n",
       "      <td>0.790898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.757327</td>\n",
       "      <td>0.867012</td>\n",
       "      <td>0.803877</td>\n",
       "      <td>0.820229</td>\n",
       "      <td>0.789619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3812adc8d5e24938b75388fa75680fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433f3f64f68a48c3a77d39ace5204934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e5c8ba96e34343bc8152beabfe3b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afe91b5228049628ef1c8614e305c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32e515831454ee88f961ca1aea8e58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb46234cdd744dbe94dec0d0db9a3428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50012e89b7c24151b6802a633acebf91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8391534391534392, 'f1': 0.7709606897355848, 'precision': 0.8113838229555018, 'recall': 0.741662180164854}, 'Instagram Data': {'accuracy': 0.6842105263157895, 'f1': 0.6337438661966964, 'precision': 0.696664216887147, 'recall': 0.6177994069422641}, 'Smoke Stop Forum': {'accuracy': 0.7701317715959004, 'f1': 0.668025231545586, 'precision': 0.7283071868632068, 'recall': 0.6352570104676846}, 'Synthetic GPT3 Data': {'accuracy': 0.8513513513513513, 'f1': 0.7857142857142857, 'precision': 0.7637254901960784, 'recall': 0.8127798127798127}, 'Health Coach Dialogue Corpus': {'accuracy': 0.6948818897637795, 'f1': 0.6934663902405838, 'precision': 0.727261217948718, 'recall': 0.695568483803778}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.825, 'f1': 0.833719107896323, 'precision': 0.836559295103279, 'recall': 0.861111111111111}, 'Optifast Mock-Chatbot': {'accuracy': 0.7777777777777778, 'f1': 0.6585765488991296, 'precision': 0.65030082243197, 'recall': 0.6680672268907563}}\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/5236eea09283e87ba7c16d0571a12520ed4f076869f3d943fdbfaaa34b71e419.953a553bf3928a893b8cacf8d8c46ce6c565c095f062120aa0773821285cde25\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5206\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.481513</td>\n",
       "      <td>0.835640</td>\n",
       "      <td>0.772952</td>\n",
       "      <td>0.764335</td>\n",
       "      <td>0.782484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.358800</td>\n",
       "      <td>0.584823</td>\n",
       "      <td>0.839100</td>\n",
       "      <td>0.782858</td>\n",
       "      <td>0.776240</td>\n",
       "      <td>0.790422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.832603</td>\n",
       "      <td>0.840830</td>\n",
       "      <td>0.783703</td>\n",
       "      <td>0.794761</td>\n",
       "      <td>0.773747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c7756dc7784205bbe8d3e47b783c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cda0820a0f4446fa237edf911efa950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a3b69504564a7aadacecaf0f7bb366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e139c6e8d4e4d6dbc1988b37bcf591a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c257cc6d9a53450eb230a77b39bd2e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a6ef527c6f4fa9a8e971fc748d5730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24be756817c54491ae7f0dbb619ad6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8402116402116402, 'f1': 0.7652990177320341, 'precision': 0.8091174611604339, 'recall': 0.7347299660133885}, 'Instagram Data': {'accuracy': 0.6831140350877193, 'f1': 0.6453789098987754, 'precision': 0.6905919557601138, 'recall': 0.6308341182626896}, 'Smoke Stop Forum': {'accuracy': 0.7906295754026355, 'f1': 0.7122802896848698, 'precision': 0.7507577294552341, 'recall': 0.6895731297416691}, 'Synthetic GPT3 Data': {'accuracy': 0.9054054054054054, 'f1': 0.8852599388379204, 'precision': 0.8924242424242425, 'recall': 0.8789173789173789}, 'Health Coach Dialogue Corpus': {'accuracy': 0.7106299212598425, 'f1': 0.7084966947935839, 'precision': 0.7572201420626617, 'recall': 0.7116892911010558}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.7625, 'f1': 0.7475213675213674, 'precision': 0.7790032679738562, 'recall': 0.7887205387205386}, 'Optifast Mock-Chatbot': {'accuracy': 0.7555555555555555, 'f1': 0.6179988033646571, 'precision': 0.6092592592592593, 'recall': 0.6294428882664177}}\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/5236eea09283e87ba7c16d0571a12520ed4f076869f3d943fdbfaaa34b71e419.953a553bf3928a893b8cacf8d8c46ce6c565c095f062120aa0773821285cde25\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5205\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.579800</td>\n",
       "      <td>0.530547</td>\n",
       "      <td>0.816926</td>\n",
       "      <td>0.745217</td>\n",
       "      <td>0.765825</td>\n",
       "      <td>0.729232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>0.695578</td>\n",
       "      <td>0.822107</td>\n",
       "      <td>0.766868</td>\n",
       "      <td>0.774124</td>\n",
       "      <td>0.760237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.956101</td>\n",
       "      <td>0.823834</td>\n",
       "      <td>0.761881</td>\n",
       "      <td>0.771485</td>\n",
       "      <td>0.757076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 579\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a716ee57c9af422198f51abb4cab31af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15888df61c524e8b9e828ddddea7cd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09bc348a7764cacab9a92204058a953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ba3a3544bd4a329713bc221ed2205e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb424e71b7445778c4c6c9c4e786bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5535fe514a644ea992144aa833c727e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e8131799764918bdd118eddc08dd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8306878306878307, 'f1': 0.7522476775740259, 'precision': 0.7875998754440037, 'recall': 0.7262843613110993}, 'Instagram Data': {'accuracy': 0.6984649122807017, 'f1': 0.6579345708803577, 'precision': 0.7159999376763655, 'recall': 0.6402818768533054}, 'Smoke Stop Forum': {'accuracy': 0.7950219619326501, 'f1': 0.7076518045292838, 'precision': 0.7454690181417658, 'recall': 0.6829588014981273}, 'Synthetic GPT3 Data': {'accuracy': 0.8918918918918919, 'f1': 0.8336427939876215, 'precision': 0.8058333333333333, 'recall': 0.870234703568037}, 'Health Coach Dialogue Corpus': {'accuracy': 0.6830708661417323, 'f1': 0.6799667175369531, 'precision': 0.7237186185462048, 'recall': 0.6840515693456869}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.8375, 'f1': 0.8395454545454545, 'precision': 0.8452380952380952, 'recall': 0.8695286195286195}, 'Optifast Mock-Chatbot': {'accuracy': 0.8, 'f1': 0.71432794847429, 'precision': 0.6981481481481482, 'recall': 0.7347338935574229}}\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/5236eea09283e87ba7c16d0571a12520ed4f076869f3d943fdbfaaa34b71e419.953a553bf3928a893b8cacf8d8c46ce6c565c095f062120aa0773821285cde25\n",
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 5206\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1953' max='1953' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1953/1953 13:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.595600</td>\n",
       "      <td>0.420411</td>\n",
       "      <td>0.854671</td>\n",
       "      <td>0.747237</td>\n",
       "      <td>0.748069</td>\n",
       "      <td>0.746428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>0.599168</td>\n",
       "      <td>0.856401</td>\n",
       "      <td>0.755462</td>\n",
       "      <td>0.767184</td>\n",
       "      <td>0.749490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.722086</td>\n",
       "      <td>0.851211</td>\n",
       "      <td>0.757490</td>\n",
       "      <td>0.769258</td>\n",
       "      <td>0.748123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to preproc_forum/checkpoint-500\n",
      "Configuration saved in preproc_forum/checkpoint-500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1000\n",
      "Configuration saved in preproc_forum/checkpoint-1000/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1000/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to preproc_forum/checkpoint-1500\n",
      "Configuration saved in preproc_forum/checkpoint-1500/config.json\n",
      "Model weights saved in preproc_forum/checkpoint-1500/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 578\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Using custom data configuration default-da19272670e01c57\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b88c25375d744508b82d22a83f7d524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-da19272670e01c57/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-49f446534e9c7ad2.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize, index. If to_tokenize, index are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 945\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-11e191c71f6179f0\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c85844fdf334cd1b0ff6d0404e9dbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-11e191c71f6179f0/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-f52a8aa5c5c56f53.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 912\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5d25b3056b36df9f\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4e3948551f4f08b7fac680e4dbd878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-5d25b3056b36df9f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-93d159c804130ec1.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 683\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-94115a684900529a\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562057441da34dffab78cc11832d6efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-94115a684900529a/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-30b6cd8d48600414.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 74\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c6c2f0a3b6aae88\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc85ba1e59b4113b6712ea9f7389eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-7c6c2f0a3b6aae88/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-9d98b1c3abf2b770.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 508\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e6e273cc3fbc395d\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43ad3120ae94a529d121d32f4d585d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-e6e273cc3fbc395d/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-668eedf2885c9490.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-25828d5db892e0c9\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e87490c804b4bbfa4a3da6a3abff168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-25828d5db892e0c9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-6bb3ef8378fa71e0.arrow\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: to_tokenize. If to_tokenize are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 90\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to classif/paraphrased_lower_4_20_sim/model\n",
      "Configuration saved in classif/paraphrased_lower_4_20_sim/model/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GLoHBCD': {'accuracy': 0.8232804232804233, 'f1': 0.7439701489815597, 'precision': 0.7678629614113485, 'recall': 0.7249699696223759}, 'Instagram Data': {'accuracy': 0.6896929824561403, 'f1': 0.6580654982202624, 'precision': 0.6803515859717436, 'recall': 0.6489174952032095}, 'Smoke Stop Forum': {'accuracy': 0.7818448023426061, 'f1': 0.7008760032853082, 'precision': 0.7030087119894506, 'recall': 0.6990756746374723}, 'Synthetic GPT3 Data': {'accuracy': 0.8918918918918919, 'f1': 0.866235167206041, 'precision': 0.8338835534213686, 'recall': 0.9116809116809117}, 'Health Coach Dialogue Corpus': {'accuracy': 0.7519685039370079, 'f1': 0.7525183435137676, 'precision': 0.777143510720153, 'recall': 0.753038138332256}, 'DARN-CT-based Wizard of Oz Dialogues': {'accuracy': 0.8, 'f1': 0.8195847362514028, 'precision': 0.8295260295260295, 'recall': 0.8409090909090908}, 'Optifast Mock-Chatbot': {'accuracy': 0.7888888888888889, 'f1': 0.6985063752276868, 'precision': 0.6841572504708098, 'recall': 0.7294428882664176}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in classif/paraphrased_lower_4_20_sim/model/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-german-cased\", num_labels=3)\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=forum_trains[i], eval_dataset=forum_vals[i], compute_metrics=compute_metrics)\n",
    "    trainer.train()\n",
    "    metrics[i] = {}\n",
    "    forum_preds = load_predict_testset(\"label_test.csv\", trainer=trainer)\n",
    "    insta_preds = load_predict_testset(\"../MI_Data/Bert_Finetuning/06_instagram_data/instagram_labels.csv\", trainer=trainer)\n",
    "    nonsmoking_preds = load_predict_testset(\"../MI_Data/Bert_Finetuning/03_non_smoking/nichtraucher_labels_v2.csv\", trainer=trainer)\n",
    "    synth_preds = load_predict_testset(\"../MI_Data/Bert_Finetuning/04_synthetic/output_labels.csv\", trainer=trainer)\n",
    "    virtualcoach_preds = load_predict_testset(\"../MI_Data/Bert_Finetuning/07_VirtualCoachData/virtual_coach_labels.csv\", trainer=trainer)\n",
    "    WoZ_preds = load_predict_testset(\"../MI_Data/Bert_Finetuning/08_WoZ/WoZ_labels.csv\", trainer=trainer)\n",
    "    optifast_preds = load_predict_testset(\"../MI_Data/Bert_Finetuning/05_optifast/optifast_labels.csv\", trainer=trainer)\n",
    "    metrics[i][\"GLoHBCD\"] = compute_test_metrics(forum_preds, 'macro')\n",
    "    metrics[i][\"Instagram Data\"] = compute_test_metrics(insta_preds, 'macro')\n",
    "    metrics[i][\"Smoke Stop Forum\"] = compute_test_metrics(nonsmoking_preds, 'macro')\n",
    "    metrics[i][\"Synthetic GPT3 Data\"] = compute_test_metrics(synth_preds, 'macro')\n",
    "    metrics[i][\"Health Coach Dialogue Corpus\"] = compute_test_metrics(virtualcoach_preds, 'macro')\n",
    "    metrics[i][\"DARN-CT-based Wizard of Oz Dialogues\"] = compute_test_metrics(WoZ_preds, 'macro')\n",
    "    metrics[i][\"Optifast Mock-Chatbot\"] = compute_test_metrics(optifast_preds, 'macro')\n",
    "    print(metrics[i])\n",
    "\n",
    "trainer.save_model(\"classif/paraphrased_lower_4_20_sim/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>GLoHBCD</th>\n",
       "      <td>0.833862</td>\n",
       "      <td>0.744505</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.712752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instagram Data</th>\n",
       "      <td>0.664474</td>\n",
       "      <td>0.605489</td>\n",
       "      <td>0.661119</td>\n",
       "      <td>0.593664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smoke Stop Forum</th>\n",
       "      <td>0.773060</td>\n",
       "      <td>0.684405</td>\n",
       "      <td>0.736208</td>\n",
       "      <td>0.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synthetic GPT3 Data</th>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.844261</td>\n",
       "      <td>0.828067</td>\n",
       "      <td>0.870235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health Coach Dialogue Corpus</th>\n",
       "      <td>0.651575</td>\n",
       "      <td>0.644870</td>\n",
       "      <td>0.726267</td>\n",
       "      <td>0.655699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                accuracy        f1  precision    recall\n",
       "0 GLoHBCD                       0.833862  0.744505   0.794684  0.712752\n",
       "  Instagram Data                0.664474  0.605489   0.661119  0.593664\n",
       "  Smoke Stop Forum              0.773060  0.684405   0.736208  0.654000\n",
       "  Synthetic GPT3 Data           0.891892  0.844261   0.828067  0.870235\n",
       "  Health Coach Dialogue Corpus  0.651575  0.644870   0.726267  0.655699"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame.from_dict({(i,j): metrics[i][j] \n",
    "                           for i in metrics.keys() \n",
    "                           for j in metrics[i].keys()},\n",
    "                       orient='index')\n",
    "\n",
    "\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"Evaluation/lower_4_20_new_datasets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8264550264550264,\n",
       " 'f1': 0.7429343858755623,\n",
       " 'precision': 0.7662756633344868,\n",
       " 'recall': 0.7259660027039706}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_test_metrics(forum_test, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(forum_test.label_ids, forum_test.predictions.argmax(-1))\n",
    "show_confusion_matrix(cm, normalized=True, class_names=[\"R\", \"TS\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify synthetic data with confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_train = pd.read_csv(\"synthetic_train_gpt_labels_as_qs.csv\", index_col=\"Unnamed: 0\")\n",
    "gpt_test = pd.read_csv(\"synthetic_test_gpt_labels_as_qs.csv\", index_col=\"Unnamed: 0\")\n",
    "sentences_train = gpt_train[\"Sentence\"].to_list()\n",
    "sentences_test = gpt_test[\"Sentence\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_train = np.array_split(sentences_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Ich denke, ich habe mich schon immer ein bisschen zu viel gefhlt.',\n",
       "       ' Ich finde es wichtig mein Gewicht zu reduzieren, da ich einige gesundheitliche Probleme habe.',\n",
       "       ' Ich muss wieder zurck zu meinen Wurzeln gehen.', ...,\n",
       "       ' Ich wei einfach nicht, was ich tun soll.', ' Hallo!',\n",
       "       ' Ich vermeide Fett, Zucker, Salz und Alkohol.'], dtype='<U256')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"classifs/forum_only/model\", local_files_only=True).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0_scores = []\n",
    "label_1_scores = []\n",
    "label_2_scores = []\n",
    "\n",
    "for entry in splitted_train:\n",
    "    print(entry)\n",
    "    with pipe.device_placement():\n",
    "        torch.cuda.empty_cache()\n",
    "        predictions_train = pipe(list(entry), truncation=True, batch_size=4)\n",
    "        for entry in predictions_train:\n",
    "            label_0_scores.append(entry[0]['score'])\n",
    "            label_1_scores.append(entry[1]['score'])\n",
    "            label_2_scores.append(entry[2]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(label_0_scores)\n",
    "pred_train_df = pd.DataFrame({\"Sentence\": sentences_train, \"0_R\":label_0_scores, \"1_TS\": label_1_scores, \"2_C\": label_2_scores })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_df.to_csv(\"synthetic_train_predicted_confidence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_test = np.array_split(sentences_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Ich wnsche mir mehr Kontrolle ber meine Ernhrung.'\n",
      " ' Ich habe mich ein wenig gesnder ernhrt.'\n",
      " ' Welche Mglichkeiten siehst du, um etwas gegen dieses Gefhl der Anstrengung zu unternehmen?'\n",
      " ...\n",
      " ' Ich wrde gerne wieder mehr Sport treiben, aber ich wei nicht, wie ich das anfangen soll.'\n",
      " ' Ich msste mehr Zeit haben um mich zu bewegen.'\n",
      " ' Ich habe einige Wochen zuvor begonnen, meine Ernhrung umzustellen.']\n",
      "[' Ich bin so mde von der ganzen Arbeit, die ich in meinen Krper investiere und ich mchte endlich Ergebnisse sehen.'\n",
      " ' Ich mchte gesund leben und mich auch so fhlen.'\n",
      " ' Auch die Geschwindigkeit, mit der ich esse, knnte ich einschrnken.'\n",
      " ... ' Hallo!' ' Meine Ernhrung hat sich sehr verbessert.'\n",
      " ' Ich knnte mein Essen einfach nur ansehen und dann wsste ich, wie viel ich esse.']\n"
     ]
    }
   ],
   "source": [
    "label_0_scores = []\n",
    "label_1_scores = []\n",
    "label_2_scores = []\n",
    "\n",
    "for entry in splitted_test:\n",
    "    print(entry)\n",
    "    with pipe.device_placement():\n",
    "        torch.cuda.empty_cache()\n",
    "        predictions_train = pipe(list(entry), truncation=True, batch_size=4)\n",
    "        for entry in predictions_train:\n",
    "            label_0_scores.append(entry[0]['score'])\n",
    "            label_1_scores.append(entry[1]['score'])\n",
    "            label_2_scores.append(entry[2]['score'])\n",
    "    \n",
    "pred_test_df = pd.DataFrame({\"Sentence\": sentences_test, \"0_R\":label_0_scores, \"1_TS\": label_1_scores, \"2_C\": label_2_scores })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d049b7dd45b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"synthetic_test_predicted_confidence.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_test_df' is not defined"
     ]
    }
   ],
   "source": [
    "pred_test_df.to_csv(\"synthetic_test_predicted_confidence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-72b5b6a0301140a8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/jovyan/.cache/huggingface/datasets/csv/default-72b5b6a0301140a8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a60f9bc4db648c9840a7ee52e212e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febea0d6b5d84d2d8b91752587bfb526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/jovyan/.cache/huggingface/datasets/csv/default-72b5b6a0301140a8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd484af114c4abfa56d2022cceedbf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-72b5b6a0301140a8\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-72b5b6a0301140a8/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f546c8e9db5243249e2878e8adc1eae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab4880acd6247fcb432eaa9a4aed638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898efd4b4e484754bf30701ca4df957d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742de65c4a5b4072b2ec8604cece7c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468b1622d79c43758b1b67b0ca89dcfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8455ffcde5a04a119fe29291d30761c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b055123f3ddc48bbb6ccf4d20480079a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb987c8f6e3a4643a7c86e640e4be34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fc9dec14cd4ad2adcc9ffb420fb553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b4bc4faa314bf48fb8d832a5fcc6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7031992a216412abb7b92efd07f5084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6164afb276834c0a87ebd7133887c6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47c5c77a8554f5a836cdf02aec91cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a320831fe5422286e33263fbaeef0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c4c7ae1abd48bbbe59906bc7ae05f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e3337c42d147b988486ac91225be8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc0a9b3c5854073b9752219860b0e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52eb65a3c3b4279885f39c665c3f1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9590b52ed644e9d8c4710528b8270b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830e4566e87d49c4a978b08c796285be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1cf3f205f14f2c8ea86d04d8090257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3059' max='3585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3059/3585 18:09 < 03:07, 2.80 it/s, Epoch 2.56/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.817654</td>\n",
       "      <td>0.783783</td>\n",
       "      <td>0.631480</td>\n",
       "      <td>0.621836</td>\n",
       "      <td>0.633728</td>\n",
       "      <td>0.622887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.709786</td>\n",
       "      <td>0.760802</td>\n",
       "      <td>0.664467</td>\n",
       "      <td>0.664638</td>\n",
       "      <td>0.680386</td>\n",
       "      <td>0.665189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3500 < 3585; dropping {'train/loss': 0.54496630859375, 'train/learning_rate': 1.1446119486320492e-06, 'train/epoch': 2.931323283082077}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3582 < 3585; dropping {'eval/loss': 0.9245823621749878, 'eval/accuracy': 0.6365348399246704, 'eval/f1': 0.6317549258129733, 'eval/precision': 0.6393461699061054, 'eval/recall': 0.6392218454953957, 'train/epoch': 3.0}.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step must only increase in log calls.  Step 3582 < 3585; dropping {'train/total_flos': 9602768188588032, 'train/epoch': 3.0}.\n",
      "Using custom data configuration default-ac5cb7352c4ec37c\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-ac5cb7352c4ec37c/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3cdfb6d6434942a532ae1b678ef06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-ac5cb7352c4ec37c/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-32020e421c50ad77.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='356' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a69c280ab7593910\n",
      "Reusing dataset csv (/home/jovyan/.cache/huggingface/datasets/csv/default-a69c280ab7593910/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4254a3d645514220b794f8a4664e75fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jovyan/.cache/huggingface/datasets/csv/default-a69c280ab7593910/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-781474f715c0055e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forum: \n",
      "{'accuracy': 0.4973821989528796, 'f1': 0.4968102332403128, 'precision': 0.5303703703703704, 'recall': 0.5557579515799809}\n",
      "Synthetic: \n",
      "{'accuracy': 0.6661642803315749, 'f1': 0.664107899905828, 'precision': 0.6710721623607286, 'recall': 0.6677061986680758}\n"
     ]
    }
   ],
   "source": [
    "forum_vals, forum_trains = load_and_tokenize_training_set(\"sublabels/train_sublabels_synthetic_noR.csv\")\n",
    "training_args = TrainingArguments(\"test\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "for i in range(2):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-german-cased\", num_labels=3)\n",
    "    trainer = Trainer(model=model, args=training_args, train_dataset=forum_trains[i], eval_dataset=forum_vals[i], compute_metrics=compute_metrics)\n",
    "    trainer.train()\n",
    "    forum_preds = load_predict_testset(\"sublabels/sublabels_forum_test_noR.csv\", trainer=trainer)\n",
    "    synthetic_preds = load_predict_testset(\"sublabels/test_sublabels_synthetic_noR.csv\", trainer=trainer)\n",
    "    print(\"Forum: \")\n",
    "    print(compute_test_metrics(forum_preds, 'macro'))\n",
    "    print(\"Synthetic: \")\n",
    "    print(compute_test_metrics(synthetic_preds, 'macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
