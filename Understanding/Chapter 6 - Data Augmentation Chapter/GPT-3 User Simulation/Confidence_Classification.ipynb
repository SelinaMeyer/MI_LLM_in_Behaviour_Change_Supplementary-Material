{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.0.0\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install datasets\n",
    "!pip install Sentencepiece\n",
    "!pip install -q torch==1.4.0 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
    "    \n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import keras\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functions import *\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify synthetic data with confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_train = pd.read_csv(\"2-synthetic-only/synthetic_train_gpt_labels_as_qs.csv\", index_col=\"Unnamed: 0\")\n",
    "#gpt_test = pd.read_csv(\"synthetic_test_gpt_labels_as_qs.csv\", index_col=\"Unnamed: 0\")\n",
    "sentences_train = gpt_train[\"Sentence\"].to_list()\n",
    "#sentences_test = gpt_test[\"Sentence\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_train = np.array_split(sentences_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Ich denke, ich habe mich schon immer ein bisschen zu viel gefühlt.',\n",
       "       ' Ich finde es wichtig mein Gewicht zu reduzieren, da ich einige gesundheitliche Probleme habe.',\n",
       "       ' Ich muss wieder zurück zu meinen Wurzeln gehen.', ...,\n",
       "       ' Ich weiß einfach nicht, was ich tun soll.', ' Hallo!',\n",
       "       ' Ich vermeide Fett, Zucker, Salz und Alkohol.'], dtype='<U256')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "cuda = torch.device('cuda')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"classifs/forum_only/model\", local_files_only=True).cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0_scores = []\n",
    "label_1_scores = []\n",
    "label_2_scores = []\n",
    "\n",
    "for entry in splitted_train:\n",
    "    with pipe.device_placement():\n",
    "        torch.cuda.empty_cache()\n",
    "        predictions_train = pipe(list(entry), truncation=True, batch_size=4)\n",
    "        for entry in predictions_train:\n",
    "            label_0_scores.append(entry[0]['score'])\n",
    "            label_1_scores.append(entry[1]['score'])\n",
    "            label_2_scores.append(entry[2]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(label_0_scores)\n",
    "pred_train_df = pd.DataFrame({\"Sentence\": sentences_train, \"0_R\":label_0_scores, \"1_TS\": label_1_scores, \"2_C\": label_2_scores })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_df.to_csv(\"gpt_predictions/8_percent_synthetic_predicted_confidence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_test = np.array_split(sentences_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Ich wünsche mir mehr Kontrolle über meine Ernährung.'\n",
      " ' Ich habe mich ein wenig gesünder ernährt.'\n",
      " ' Welche Möglichkeiten siehst du, um etwas gegen dieses Gefühl der Anstrengung zu unternehmen?'\n",
      " ...\n",
      " ' Ich würde gerne wieder mehr Sport treiben, aber ich weiß nicht, wie ich das anfangen soll.'\n",
      " ' Ich müsste mehr Zeit haben um mich zu bewegen.'\n",
      " ' Ich habe einige Wochen zuvor begonnen, meine Ernährung umzustellen.']\n",
      "[' Ich bin so müde von der ganzen Arbeit, die ich in meinen Körper investiere und ich möchte endlich Ergebnisse sehen.'\n",
      " ' Ich möchte gesund leben und mich auch so fühlen.'\n",
      " ' Auch die Geschwindigkeit, mit der ich esse, könnte ich einschränken.'\n",
      " ... ' Hallo!' ' Meine Ernährung hat sich sehr verbessert.'\n",
      " ' Ich könnte mein Essen einfach nur ansehen und dann wüsste ich, wie viel ich esse.']\n"
     ]
    }
   ],
   "source": [
    "label_0_scores = []\n",
    "label_1_scores = []\n",
    "label_2_scores = []\n",
    "\n",
    "for entry in splitted_test:\n",
    "    print(entry)\n",
    "    with pipe.device_placement():\n",
    "        torch.cuda.empty_cache()\n",
    "        predictions_train = pipe(list(entry), truncation=True, batch_size=4)\n",
    "        for entry in predictions_train:\n",
    "            label_0_scores.append(entry[0]['score'])\n",
    "            label_1_scores.append(entry[1]['score'])\n",
    "            label_2_scores.append(entry[2]['score'])\n",
    "    \n",
    "pred_test_df = pd.DataFrame({\"Sentence\": sentences_test, \"0_R\":label_0_scores, \"1_TS\": label_1_scores, \"2_C\": label_2_scores })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d049b7dd45b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_test_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"synthetic_test_predicted_confidence.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_test_df' is not defined"
     ]
    }
   ],
   "source": [
    "pred_test_df.to_csv(\"synthetic_test_predicted_confidence.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
